from fastapi import APIRouter, HTTPException, Path, Query
from typing import Optional, List, Any, Dict
from uuid import uuid4
# ã‚µãƒ¼ãƒ“ã‚¹å±¤ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from backend.app.services.ai_service import get_ai_response_with_simple_chart # For Development, add backend. path
# æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
# from backend.app.services.ai_service_refactored import get_ai_response_with_simple_chart
from backend.app.services.conversation_service import get_conversation_service

from backend.app.api.schemas import QnARequest # For Development, add backend. path
from backend.app.utils.structured_logger import get_logger
from backend.app.services.monitoring_service import get_monitoring_service
import logging
import time

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
structured_logger = get_logger("diamond-lens")
monitoring = get_monitoring_service()

# APIRouterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
# ã“ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã¯ã€FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä»–ã®éƒ¨åˆ†ã¨ã¯ç‹¬ç«‹ã—ã¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©ã§ãã¾ã™ã€‚
router = APIRouter()


 
@router.post(
    "/qa/player-stats",
    response_model=Dict[str, Any],
    summary="é¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹Q&Aã‚’AIã§ç”Ÿæˆï¼ˆä¼šè©±å±¥æ­´å¯¾å¿œï¼‰",
    description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ã€AIãŒé¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦ä»£åè©ã‚„çœç•¥ã‚’è‡ªå‹•è§£æ±ºã—ã¾ã™ã€‚",
    tags=["players"] # é¸æ‰‹ã«é–¢é€£ã™ã‚‹ãŸã‚ 'players' ã‚¿ã‚°ã‚’ä½¿ç”¨
)
async def get_player_stats_qna_endpoint(
    request: QnARequest # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‹ã‚‰QnARequestãƒ¢ãƒ‡ãƒ«ã‚’å—ã‘å–ã‚‹
    # query: str,
    # season: Optional[int] = None
) -> Dict[str, Any]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ã€AIãŒé¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    ä¼šè©±å±¥æ­´æ©Ÿèƒ½: session_idã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€éå»ã®ä¼šè©±ã‚’å‚ç…§ã—ã¦ã€Œå½¼ã€ãªã©ã®ä»£åè©ã‚’è‡ªå‹•è§£æ±ºã—ã¾ã™ã€‚
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    session_id = request.session_id or str(uuid4())

    start_time = time.time()
    logger.info(f"ğŸš€ Request received: query='{request.query}', season={request.season}, session_id={session_id}")

    # Structured logging for query
    structured_logger.info(
        "Player stats query received",
        query=request.query,
        season=request.season
    )

    try:
        logger.info("ğŸ“Š Calling BigQuery service...")
        bq_start = time.time()

        # BigQueryå‡¦ç†
        # ... your BigQuery code ...

        bq_end = time.time()
        bq_latency = (bq_end - bq_start) * 1000
        logger.info(f"ğŸ“Š BigQuery completed in {bq_end - bq_start:.2f} seconds")

        logger.info("ğŸ¤– Calling Gemini API...")
        gemini_start = time.time()

        # ai_response = get_ai_response_for_qna(request.query, request.season)
        # Use chart-enabled version for enhanced visualization (ä¼šè©±å±¥æ­´å¯¾å¿œ)
        ai_response = get_ai_response_with_simple_chart(
            request.query,
            request.season,
            session_id=session_id  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’æ¸¡ã™ â˜…
        )

        gemini_end = time.time()
        logger.info(f"ğŸ¤– Gemini API completed in {gemini_end - gemini_start:.2f} seconds")

        total_time = time.time() - start_time
        total_time_ms = total_time * 1000
        logger.info(f"âœ… Total request completed in {total_time:.2f} seconds")

        # Record processing metrics
        if ai_response and ai_response.get("query_info"):
            query_type = ai_response["query_info"].get("query_type", "unknown")
            monitoring.record_query_processing_time(query_type, total_time_ms)
            monitoring.record_bigquery_latency(query_type, bq_latency)

            structured_logger.info(
                "Query processed successfully",
                query_type=query_type,
                processing_time_ms=round(total_time_ms, 2),
                bigquery_latency_ms=round(bq_latency, 2)
            )

        if ai_response is None:
            logger.error("âŒ AI response is None")
            monitoring.record_api_error("/qa/player-stats", "null_response")
            structured_logger.error("AI response is None")
            raise HTTPException(status_code=500, detail="Failed to generate AI response.")

        # â˜… ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å«ã‚ã‚‹ â˜…
        ai_response["session_id"] = session_id

        return ai_response

    except Exception as e:
        elapsed_time = time.time() - start_time
        logger.error(f"âŒ Error after {elapsed_time:.2f} seconds: {str(e)}")

        # Determine error type
        error_type = "unknown_error"
        if "validation" in str(e).lower():
            error_type = "validation_error"
        elif "bigquery" in str(e).lower():
            error_type = "bigquery_error"
        elif "llm" in str(e).lower() or "gemini" in str(e).lower():
            error_type = "llm_error"

        monitoring.record_api_error("/qa/player-stats", error_type)
        structured_logger.error(
            "Query processing failed",
            error_type=error_type,
            error_message=str(e),
            elapsed_time_ms=round(elapsed_time * 1000, 2)
        )

        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

# â˜…â˜…â˜… æ–°è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: ä¼šè©±å±¥æ­´å–å¾— â˜…â˜…â˜…
@router.get(
    "/qa/history/{session_id}",
    response_model=Dict[str, Any],
    summary="ä¼šè©±å±¥æ­´ã‚’å–å¾—",
    description="æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¾ã™ã€‚",
    tags=["players"]
)
async def get_chat_history(session_id: str):
    """
    æŒ‡å®šã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—

    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

    Returns:
        ä¼šè©±å±¥æ­´ã®ãƒªã‚¹ãƒˆ
    """
    conv_service = get_conversation_service()
    history = conv_service.get_chat_history(session_id)

    return {
        "session_id": session_id,
        "history": history,
        "count": len(history)
    }


# â˜…â˜…â˜… æ–°è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢ â˜…â˜…â˜…
@router.delete(
    "/qa/history/{session_id}",
    response_model=Dict[str, Any],
    summary="ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢",
    description="æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã€‚",
    tags=["players"]
)
async def clear_chat_history(session_id: str):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤

    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

    Returns:
        å‰Šé™¤æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    conv_service = get_conversation_service()
    conv_service.clear_session(session_id)

    logger.info(f"ğŸ—‘ï¸ Session cleared: {session_id}")

    return {
        "message": "Session cleared successfully",
        "session_id": session_id
    }


# ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@router.get("/test")
async def test_endpoint():
    return {"status": "ok", "message": "Backend is working"}

@router.post("/test-post")
async def test_post_endpoint(request: dict):
    return {"received": request, "timestamp": time.time()}