from fastapi import APIRouter, HTTPException, Request
from typing import Optional, List, Any, Dict
from uuid import uuid4
# ã‚µãƒ¼ãƒ“ã‚¹å±¤ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from backend.app.services.ai_service import get_ai_response_with_simple_chart # For Development, add backend. path
# æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
# from backend.app.services.ai_service_refactored import get_ai_response_with_simple_chart
from backend.app.services.conversation_service import get_conversation_service

from backend.app.api.schemas import QnARequest # For Development, add backend. path
from backend.app.utils.structured_logger import get_logger
from backend.app.services.monitoring_service import get_monitoring_service
from backend.app.services.ai_agent_service import run_mlb_agent
from backend.app.services.llm_logger_service import get_llm_logger, LLMLogEntry
from backend.app.config.prompt_registry import get_prompt_version
from backend.app.middleware.request_id import get_request_id
from backend.app.core.exceptions import PromptInjectionError
import logging
import time

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
structured_logger = get_logger("diamond-lens")
monitoring = get_monitoring_service()
llm_logger = get_llm_logger()

# APIRouterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
# ã“ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã¯ã€FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä»–ã®éƒ¨åˆ†ã¨ã¯ç‹¬ç«‹ã—ã¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©ã§ãã¾ã™ã€‚
router = APIRouter()


 
@router.post(
    "/qa/player-stats",
    response_model=Dict[str, Any],
    summary="é¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹Q&Aã‚’AIã§ç”Ÿæˆï¼ˆä¼šè©±å±¥æ­´å¯¾å¿œï¼‰",
    description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ã€AIãŒé¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦ä»£åè©ã‚„çœç•¥ã‚’è‡ªå‹•è§£æ±ºã—ã¾ã™ã€‚",
    tags=["players"] # é¸æ‰‹ã«é–¢é€£ã™ã‚‹ãŸã‚ 'players' ã‚¿ã‚°ã‚’ä½¿ç”¨
)
async def get_player_stats_qna_endpoint(
    request_body: QnARequest, # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‹ã‚‰QnARequestãƒ¢ãƒ‡ãƒ«ã‚’å—ã‘å–ã‚‹
    request: Request,
    # query: str,
    # season: Optional[int] = None
) -> Dict[str, Any]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ã€AIãŒé¸æ‰‹/ãƒãƒ¼ãƒ ã®çµ±è¨ˆæƒ…å ±ã«é–¢ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    ä¼šè©±å±¥æ­´æ©Ÿèƒ½: session_idã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€éå»ã®ä¼šè©±ã‚’å‚ç…§ã—ã¦ã€Œå½¼ã€ãªã©ã®ä»£åè©ã‚’è‡ªå‹•è§£æ±ºã—ã¾ã™ã€‚
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    session_id = request_body.session_id or str(uuid4())
    start_time = time.time()

    # â˜… user_id ã‚’ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‹ã‚‰å–å¾—
    user_id = getattr(request.state, "user_id", "anonymous")

    # â˜… Guardrail ãƒã‚§ãƒƒã‚¯
    from backend.app.services.security_guardrail import get_security_guardrail
    guardrail = get_security_guardrail()
    is_safe, reason = guardrail.validate_and_log(request_body.query)
    if not is_safe:
        return {
            "answer": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã¯ãŠå¿œãˆã§ãã¾ã›ã‚“ã€‚MLBçµ±è¨ˆã«é–¢ã™ã‚‹è³ªå•ã‚’ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚",
            "isTable": False,
            "isChart": False,
            "session_id": session_id,
            "blocked": True,
        }
    
    # LLM ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’åˆæœŸåŒ–
    log_entry = LLMLogEntry()
    log_entry.request_id = get_request_id()
    log_entry.user_id = user_id
    log_entry.session_id = session_id
    log_entry.user_query = request_body.query
    log_entry.endpoint = "/qa/player-stats"
    log_entry.prompt_name = "parse_query"
    log_entry.prompt_version = get_prompt_version("parse_query")

    # Structured logging for query
    structured_logger.info(
        "Player stats query received",
        query=request_body.query,
        season=request_body.season
    )

    try:
        logger.info("ğŸ“Š Calling BigQuery service...")
        bq_start = time.time()

        # BigQueryå‡¦ç†
        # ... your BigQuery code ...

        bq_end = time.time()
        bq_latency = (bq_end - bq_start) * 1000
        logger.info(f"ğŸ“Š BigQuery completed in {bq_end - bq_start:.2f} seconds")

        logger.info("ğŸ¤– Calling Gemini API...")
        gemini_start = time.time()

        # ai_response = get_ai_response_for_qna(request.query, request.season)
        # Use chart-enabled version for enhanced visualization (ä¼šè©±å±¥æ­´å¯¾å¿œ)
        ai_response = get_ai_response_with_simple_chart(
            request_body.query,
            request_body.season,
            session_id=session_id  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’æ¸¡ã™ â˜…
        )

        gemini_end = time.time()
        logger.info(f"ğŸ¤– Gemini API completed in {gemini_end - gemini_start:.2f} seconds")

        # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã«çµæœã‚’è¨˜éŒ²
        log_entry.llm_latency_ms = (gemini_end - gemini_start) * 1000
        log_entry.total_latency_ms = (time.time() - start_time) * 1000
        log_entry.bigquery_latency_ms = bq_latency

        total_time = time.time() - start_time
        total_time_ms = total_time * 1000
        logger.info(f"âœ… Total request completed in {total_time:.2f} seconds")

        # Record processing metrics
        if ai_response and ai_response.get("query_info"):
            query_type = ai_response["query_info"].get("query_type", "unknown")
            log_entry.parsed_query_type = query_type
            log_entry.parsed_player_name = ai_response["query_info"].get("name")
            log_entry.parsed_season = ai_response["query_info"].get("season")
            monitoring.record_query_processing_time(query_type, total_time_ms)
            monitoring.record_bigquery_latency(query_type, bq_latency)

            structured_logger.info(
                "Query processed successfully",
                query_type=query_type,
                processing_time_ms=round(total_time_ms, 2),
                bigquery_latency_ms=round(bq_latency, 2)
            )

        if ai_response is None:
            logger.error("âŒ AI response is None")
            log_entry.success = False
            log_entry.error_type = "null_response"
            llm_logger.log(log_entry)  # ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ­ã‚°ã«è¨˜éŒ²
            monitoring.record_api_error("/qa/player-stats", "null_response")
            structured_logger.error("AI response is None")
            raise HTTPException(status_code=500, detail="Failed to generate AI response.")
        
        # æˆåŠŸæ™‚ã®ãƒ­ã‚°è¨˜éŒ²
        log_entry.response_answer = ai_response.get("answer", "")
        log_entry.response_has_table = ai_response.get("isTable", False)
        log_entry.response_has_chart = ai_response.get("isChart", False)
        log_entry.success = True
        llm_logger.log(log_entry)

        # â˜… ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å«ã‚ã‚‹ â˜…
        ai_response["session_id"] = session_id

        return ai_response

    except Exception as e:
        elapsed_time = time.time() - start_time
        logger.error(f"âŒ Error after {elapsed_time:.2f} seconds: {str(e)}")

        # Determine error type
        error_type = "unknown_error"
        if "validation" in str(e).lower():
            error_type = "validation_error"
        elif "bigquery" in str(e).lower():
            error_type = "bigquery_error"
        elif "llm" in str(e).lower() or "gemini" in str(e).lower():
            error_type = "llm_error"
        
        log_entry.success = False
        log_entry.error_type = error_type
        log_entry.error_message = str(e)
        log_entry.total_latency_ms = (time.time() - start_time) * 1000
        llm_logger.log(log_entry)  # ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ­ã‚°ã«è¨˜éŒ²

        monitoring.record_api_error("/qa/player-stats", error_type)
        structured_logger.error(
            "Query processing failed",
            error_type=error_type,
            error_message=str(e),
            elapsed_time_ms=round(elapsed_time * 1000, 2)
        )

        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

# â˜…â˜…â˜… æ–°è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: ä¼šè©±å±¥æ­´å–å¾— â˜…â˜…â˜…
@router.get(
    "/qa/history/{session_id}",
    response_model=Dict[str, Any],
    summary="ä¼šè©±å±¥æ­´ã‚’å–å¾—",
    description="æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¾ã™ã€‚",
    tags=["players"]
)
async def get_chat_history(session_id: str):
    """
    æŒ‡å®šã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—

    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

    Returns:
        ä¼šè©±å±¥æ­´ã®ãƒªã‚¹ãƒˆ
    """
    conv_service = get_conversation_service()
    history = conv_service.get_chat_history(session_id)

    return {
        "session_id": session_id,
        "history": history,
        "count": len(history)
    }


# â˜…â˜…â˜… æ–°è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢ â˜…â˜…â˜…
@router.delete(
    "/qa/history/{session_id}",
    response_model=Dict[str, Any],
    summary="ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢",
    description="æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã€‚",
    tags=["players"]
)
async def clear_chat_history(session_id: str):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤

    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

    Returns:
        å‰Šé™¤æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    conv_service = get_conversation_service()
    conv_service.clear_session(session_id)

    logger.info(f"ğŸ—‘ï¸ Session cleared: {session_id}")

    return {
        "message": "Session cleared successfully",
        "session_id": session_id
    }


@router.post(
    "/qa/agentic-stats",
    response_model=Dict[str, Any],
    summary="è‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†æãƒ»Q&A",
    description="LangGraphã‚’ç”¨ã„ãŸè‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€è¤‡é›‘ãªè³ªå•ã«å¯¾ã—ã¦è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨è«–ã‚’è¡Œã„ã€å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
    tags=["agentic"]
)
async def get_agentic_stats_endpoint(
    request: QnARequest
) -> Dict[str, Any]:
    """
    è‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆLangGraphï¼‰ã‚’èµ·å‹•ã—ã¦å›ç­”ã‚’å¾—ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚
    """
    session_id = request.session_id or str(uuid4())
    start_time = time.time()
    
    logger.info(f"ğŸ¤– Agentic Request: query='{request.query}', session_id={session_id}")
    
    try:
        # è‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ
        result_state = run_mlb_agent(request.query)
        
        # 1. å›ç­”ã®å–å¾—ï¼ˆfinal_answer ã¾ãŸã¯ æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ï¼‰
        answer = result_state.get("final_answer", "")
        if not answer:
            # final_answerãŒç©ºã®å ´åˆã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®æœ€å¾Œã®AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¢ã™
            for msg in reversed(result_state.get("messages", [])):
                if msg.type == "ai" and msg.content:
                    answer = msg.content
                    break
        
        # 2. æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆStepsï¼‰ã®æŠ½å‡ºã‚’ã‚ˆã‚ŠæŸ”è»Ÿã«
        steps = []
        for msg in result_state.get("messages", []):
            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼ˆæ€è€ƒï¼‰ã®åˆ¤å®š
            tool_calls = getattr(msg, "tool_calls", None)
            if tool_calls:
                tool_name = tool_calls[0].get("name", "ãƒ‡ãƒ¼ã‚¿æ¤œç´¢") if isinstance(tool_calls[0], dict) else getattr(tool_calls[0], "name", "ãƒ‡ãƒ¼ã‚¿æ¤œç´¢")
                steps.append({
                    "type": "thought",
                    "content": f"è¨ˆç”»: {tool_name} ã‚’å®Ÿè¡Œã—ã¦æƒ…å ±ã‚’åé›†ã—ã¾ã™ã€‚"
                })
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœï¼ˆå®Ÿè¡Œï¼‰ã®åˆ¤å®š
            elif msg.type == "tool" or hasattr(msg, "tool_call_id"):
                steps.append({
                    "type": "execution",
                    "content": "å®Ÿè¡Œ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸã€‚"
                })

        elapsed_time = time.time() - start_time
        logger.info(f"âœ… Agentic request completed in {elapsed_time:.2f} seconds. Answer length: {len(answer)}, Steps: {len(steps)}")
        
        return {
            "query": request.query,
            "answer": answer or "å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚",
            "steps": steps,
            "session_id": session_id,
            "processing_time_ms": round(elapsed_time * 1000, 2),
            "is_agentic": True,
            "isTable": result_state.get("isTable", False),
            "tableData": result_state.get("tableData"),
            "columns": result_state.get("columns"),
            "isTransposed": result_state.get("isTransposed", False),
            "isChart": result_state.get("isChart", False),
            "chartType": result_state.get("chartType"),
            "chartData": result_state.get("chartData"),
            "chartConfig": result_state.get("chartConfig"),
            "isMatchupCard": result_state.get("isMatchupCard", False),
            "matchupData": result_state.get("matchupData")
        }
    
    except PromptInjectionError as e:
        # Guardrailã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯ â†’ 400ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ï¼‰ã¨ã—ã¦è¿”ã™
        logger.warning(f"ğŸš¨ Guardrail blocked: {e.detected_pattern}", extra={"query": request.query[:100]})
        return {
            "query": request.query,
            "answer": e.message,  # ä¸å¯§ãªæ‹’å¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            "steps": [],
            "session_id": session_id,
            "processing_time_ms": round((time.time() - start_time) * 1000, 2),
            "is_agentic": True,
            "isTable": False,
            "isChart": False,
            "blocked": True,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å´ã§åˆ¤åˆ¥ã™ã‚‹ãƒ•ãƒ©ã‚°
            "blocked_reason": e.detected_pattern,
        }
    
    except Exception as e:
        logger.error(f"âŒ Agentic Error: {str(e)}", exc_info=True)
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯è©³ç´°ã‚’è¿”å´
        raise HTTPException(status_code=500, detail=f"Agent error: {str(e)}")


# ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@router.get("/test")
async def test_endpoint():
    return {"status": "ok", "message": "Backend is working"}

@router.post("/test-post")
async def test_post_endpoint(request: dict):
    return {"received": request, "timestamp": time.time()}