import json
from langgraph.graph import StateGraph, END
from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage
from backend.app.utils.structured_logger import get_logger
from backend.app.core.exceptions import AgentReasoningError

logger = get_logger("matchup-agent")


class MatchupAgent:
    """
    Specialized agent for matchup analysis.
    Uses existing LangGraph structure (Oracle â†’ Executor â†’ Synthesizer).
    """
    
    def __init__(self, model):
        self.raw_model = model  # For text generation (no tools)
        
        # Import and define tools first
        from ..ai_agent_service import mlb_matchup_history_tool, mlb_matchup_analytics_tool
        self.tools = [mlb_matchup_history_tool, mlb_matchup_analytics_tool]
        
        # Then bind tools to model
        self.model = model.bind_tools(self.tools)
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """Build LangGraph workflow"""
        from ..ai_agent_service import AgentState

        workflow = StateGraph(AgentState)

        # Add nodes
        workflow.add_node("oracle", self.oracle_node)
        workflow.add_node("executor", self.executor_node)
        workflow.add_node("reflection", self.reflection_node)
        workflow.add_node("synthesizer", self.synthesizer_node)

        # Add edges
        workflow.set_entry_point("oracle")
        workflow.add_conditional_edges(
            "oracle",
            self.should_continue,
            {
                "continue": "executor",
                "end": "synthesizer"
            }
        )

        # executorå®Ÿè¡Œå¾Œã€ã‚¨ãƒ©ãƒ¼/ç©ºçµæœãŒã‚ã‚Œã°reflectionã¸ã€ãªã‘ã‚Œã°oracleã¸
        workflow.add_conditional_edges(
            "executor",
            self.should_reflect,
            {
                "reflection": "reflection",
                "oracle": "oracle"
            }
        )

        workflow.add_edge("reflection", "oracle")
        workflow.add_edge("synthesizer", END)

        return workflow.compile()
    
    def should_continue(self, state):
        """Determine if we should continue or end"""
        last_message = state["messages"][-1]
        if last_message.tool_calls:
            return "continue"
        return "end"

    def should_reflect(self, state):
        """executorå®Ÿè¡Œå¾Œã€ReflectionãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        retry_count = state.get("retry_count", 0)
        max_retries = state.get("max_retries", 2)
        last_error = state.get("last_error")
        result_count = state.get("last_query_result_count", -1)

        # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¦ã„ã‚‹å ´åˆã¯ã€Reflectionã—ãªã„
        if retry_count >= max_retries:
            logger.info("Max retries reached, skipping reflection",
                        retry_count=retry_count,
                        max_retries=max_retries)
            return "oracle"

        # Do NOT retry: èªè¨¼ãƒ»ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼
        if last_error and any(keyword in last_error.lower() for keyword in [
            "permission", "access denied", "unauthorized", "forbidden"
        ]):
            logger.info("Non-retryable error detected (permission)", error=last_error)
            return "oracle"

        # Do NOT retry: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
        if last_error and "timeout" in last_error.lower():
            logger.info("Non-retryable error detected (timeout)", error=last_error)
            return "oracle"

        # Do NOT retry: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/ã‚¹ã‚­ãƒ¼ãƒã‚¨ãƒ©ãƒ¼
        if last_error and any(keyword in last_error.lower() for keyword in [
            "dataset", "schema", "not found", "does not exist"
        ]):
            logger.info("Non-retryable error detected (schema/dataset)", error=last_error)
            return "oracle"

        # Retry: SQLã‚·ãƒ³ã‚¿ãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼ã€ã‚«ãƒ©ãƒ åèª¤èªè­˜
        if last_error and any(keyword in last_error.lower() for keyword in [
            "syntax", "unrecognized", "invalid", "column", "table"
        ]):
            logger.info("Retryable error detected (SQL syntax/column)",
                        error=last_error,
                        retry_count=retry_count)
            return "reflection"

        # Retry: ç©ºçµæœï¼ˆ0è¡Œï¼‰
        if result_count == 0:
            logger.info("Empty result detected, triggering reflection",
                        retry_count=retry_count)
            return "reflection"

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: é€šå¸¸ãƒ•ãƒ­ãƒ¼ï¼ˆoracleã«æˆ»ã‚‹ï¼‰
        return "oracle"

    def oracle_node(self, state):
        """Oracle node - plans tool execution"""
        logger.info("Oracle node started", node="oracle")
        
        system_prompt = """ã‚ãªãŸã¯MLBãƒ‡ãƒ¼ã‚¿åé›†ã®å¸ä»¤å¡”ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€æœ€é©ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¨ˆç”»ã—ã¦ãã ã•ã„ã€‚
        
        **é‡è¦ãªè¡Œå‹•æŒ‡é‡:**
        1. æ‰“è€…ã¨æŠ•æ‰‹ã®ç‰¹å®šã®å¯¾æˆ¦ï¼ˆMatchupï¼‰ã«é–¢ã™ã‚‹è³ªå•ã®å ´åˆã€å¿…ãš `mlb_matchup_analytics_tool` ã¨ `mlb_matchup_history_tool` ã‚’ä½¿ç”¨ã—ã¦æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
        2. è‡ªåˆ†ã®çŸ¥è­˜ã ã‘ã§ç­”ãˆãšã€å¿…ãšBigQueryä¸Šã®ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
        3. è¤‡æ•°ã®é¸æ‰‹ã‚’æ¯”è¼ƒã™ã‚‹å ´åˆã€å„å¯¾è±¡ã«ã¤ã„ã¦å€‹åˆ¥ã‹ã¤è©³ç´°ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
        4. å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦æƒã£ãŸã¨ç¢ºä¿¡ã§ãã‚‹ã¾ã§ã€ç¹°ã‚Šè¿”ã—å®Ÿè¡Œï¼ˆcontinueï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"""
        
        prompt = [SystemMessage(content=system_prompt)] + state["messages"]
        
        try:
            response = self.model.invoke(prompt)
            return {"messages": [response]}
        except Exception as e:
            raise AgentReasoningError("AIã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", original_error=e) from e
    
    def executor_node(self, state):
        """Executor node - executes tools"""
        logger.info("Executor node started", node="executor", status="executing")

        last_message = state["messages"][-1]
        tool_outputs = []
        has_error = False
        result_count = -1
        error_message = ""

        for tool_call in last_message.tool_calls:
            tool_name = tool_call["name"]
            logger.info(f"Calling tool: {tool_name}")

            selected_tool = next((t for t in self.tools if t.name == tool_name), None)

            if selected_tool:
                result = selected_tool.invoke(tool_call["args"])
            else:
                result = {"error": f"Tool {tool_name} not found"}
                has_error = True
                error_message = result["error"]

            # ===== ã‚¨ãƒ©ãƒ¼/ç©ºçµæœã®æ¤œå‡º =====
            logger.info(f"Tool result type: {type(result).__name__}, preview: {str(result)[:200]}")

            # 1. BigQuery error
            if isinstance(result, dict) and "error" in result:
                has_error = True
                error_message = result.get("error", "Unknown error")
                logger.warning("Tool execution error detected",
                               tool_name=tool_name,
                               error=error_message)

            # 2. Empty result
            if isinstance(result, list):
                result_count = len(result)
                if result_count == 0:
                    logger.warning("Empty result detected (0 rows from list)",
                                   tool_name=tool_name,
                                   result_count=result_count)
            elif isinstance(result, dict):
                if "data" in result and isinstance(result["data"], list):
                    result_count = len(result["data"])
                    if result_count == 0:
                        logger.warning("Empty result detected (0 rows from dict)",
                                       tool_name=tool_name,
                                       result_count=result_count)
                elif result.get("answer") and "ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in result.get("answer", ""):
                    result_count = 0
                    logger.warning("Empty result detected (no data message)",
                                   tool_name=tool_name,
                                   answer_preview=result.get("answer", "")[:100])
            #==============================

            # Sanitize data (remove NaN, Infinity)
            def sanitize_data(obj):
                if isinstance(obj, list):
                    return [sanitize_data(item) for item in obj]
                elif isinstance(obj, dict):
                    return {k: sanitize_data(v) for k, v in obj.items()}
                elif isinstance(obj, float):
                    if obj != obj:  # NaN check
                        return None
                    if obj == float('inf') or obj == float('-inf'):
                        return None
                return obj

            sanitized_result = sanitize_data(result)

            tool_outputs.append(ToolMessage(
                tool_call_id=tool_call["id"],
                content=json.dumps(sanitized_result, ensure_ascii=False, default=str)
            ))

        return {
            "messages": tool_outputs,
            "last_error": error_message if has_error else None,
            "last_query_result_count": result_count
        }
    
    def reflection_node(self, state):
        """ã‚¨ãƒ©ãƒ¼ã‚„ç©ºçµæœã®å ´åˆã€LLMã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦å†è©¦è¡Œ"""
        logger.info("Reflection node started",
                    node="reflection_node",
                    status="analyzing_error",
                    retry_count=state.get("retry_count", 0))

        # Build error context
        error_context = ""
        if state.get("last_error"):
            error_context = f"""
            **ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼**:
{state['last_error']}

**ã‚¨ãƒ©ãƒ¼ã®åŸå› ã¨ã—ã¦è€ƒãˆã‚‰ã‚Œã‚‹ã“ã¨**:
- ã‚«ãƒ©ãƒ åã®èª¤èªè­˜ï¼ˆä¾‹: `player_name` ã§ã¯ãªã `name_display_first_last` ãŒæ­£ã—ã„å¯èƒ½æ€§ï¼‰
- ãƒ†ãƒ¼ãƒ–ãƒ«åã®èª¤èªè­˜
- SQLã‚·ãƒ³ã‚¿ãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼ï¼ˆJOINå¥ã€WHEREå¥ã®è¨˜è¿°ãƒŸã‚¹ç­‰ï¼‰
            """
        elif state.get("last_query_result_count") == 0:
            error_context = f"""
            **å•é¡Œ**:
ã‚¯ã‚¨ãƒªã¯æˆåŠŸã—ã¾ã—ãŸãŒã€çµæœãŒ0è¡Œã§ã—ãŸã€‚

**æ”¹å–„ã®æ–¹å‘æ€§**:
- ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ãŒå³ã—ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆä¾‹: å¹´åº¦æŒ‡å®šã€é¸æ‰‹åã®ã‚¹ãƒšãƒ«ãƒŸã‚¹ï¼‰
- WHEREå¥ã®æ¡ä»¶ã‚’ç·©å’Œã™ã‚‹ã‹ã€LIKEã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³: "{state.get('original_user_intent', '')}"
            """
        else:
            error_context = "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

        # Reflection Prompt
        reflection_prompt = f"""
        ã‚ãªãŸã¯MLBãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æã—ã€æ”¹å–„ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

{error_context}

**ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯**:
1. ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„
2. ä¿®æ­£ã—ãŸæ¡ä»¶ã§å†åº¦ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦ã¿ã¦ãã ã•ã„
3. ãã‚Œã§ã‚‚å¤±æ•—ã™ã‚‹å ´åˆã¯ã€åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆåˆ¥ã®ãƒ„ãƒ¼ãƒ«ã€åˆ¥ã®ãƒ†ãƒ¼ãƒ–ãƒ«ç­‰ï¼‰ã‚’æ¤œè¨ã—ã¦ãã ã•ã„

**é‡è¦**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã€Œ{state.get('original_user_intent', '')}ã€ã«ç­”ãˆã‚‹ãŸã‚ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        """

        # Let LLM think
        prompt = [SystemMessage(content=reflection_prompt)] + state["messages"]

        try:
            response = self.model.invoke(prompt)
            logger.info("Reflection completed",
                        has_tool_calls=bool(response.tool_calls),
                        retry_count=state.get("retry_count", 0))

            # Increment retry count
            return {
                "messages": [response],
                "retry_count": state.get("retry_count", 0) + 1
            }
        except Exception as e:
            logger.error("Reflection node error", error=str(e))
            raise AgentReasoningError("è‡ªå·±ä¿®æ­£ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", original_error=e) from e

    def synthesizer_node(self, state):
        """Synthesizer node - generates final answer"""
        logger.info("Synthesizer node started", node="synthesizer")
        
        system_prompt = """ã‚ãªãŸã¯MLBå…¬å¼ã‚·ãƒ‹ã‚¢ãƒ»ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
        æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€ä¸€ç›®ã§ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‹ã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

        **ã€å‡ºåŠ›æ§‹æˆã®å¿…é ˆãƒ«ãƒ¼ãƒ«ã€‘:**
        1. **Markdownã«ã‚ˆã‚‹æ§‹é€ åŒ–**:
           - é©åˆ‡ãªè¦‹å‡ºã—ï¼ˆ###ï¼‰ã‚’ä½¿ç”¨ã—ã€æƒ…å ±ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚
           - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®åˆ—æŒ™ã«ã¯ç®‡æ¡æ›¸ãï¼ˆ- ï¼‰ã‚’ä½¿ç”¨ã—ã€è¦–èªæ€§ã‚’é«˜ã‚ã¦ãã ã•ã„ã€‚
        2. **ãƒ—ãƒ­ã®åˆ†æã‚¨ãƒƒã‚»ãƒ³ã‚¹**:
           - å˜ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ—èª­ã§ã¯ãªãã€ã€Œãªãœãã†ãªã£ãŸã‹ã€ã€Œãã®æ•°å­—ãŒæŒã¤æ„å‘³ã€ã‚’ã‚¢ãƒŠãƒªã‚¹ãƒˆã®è¦–ç‚¹ã§ç°¡æ½”ã«æ·»ãˆã¦ãã ã•ã„ã€‚
        3. **æµæš¢ã§è‡ªç„¶ãªæ—¥æœ¬èª**:
           - **æœ€åˆã®ä¸€æ–‡ã¯å¿…ãšæ•´åˆæ€§ã®å–ã‚ŒãŸå®Œå…¨ãªæ–‡ç« ï¼ˆä¾‹ï¼šã€Œå¤§è°·é¸æ‰‹ã®ã€œã€ï¼‰ã§å§‹ã‚ã¦ãã ã•ã„ã€‚**
           - åŒã˜ä¸»èªï¼ˆå¤§è°·é¸æ‰‹ã¯ã€œï¼‰ã®é€£ç¶šä½¿ç”¨ã‚’é¿ã‘ã€æŒ‡ç¤ºèªã‚„æ¥ç¶šè©ã‚’ä½¿ã„ã“ãªã—ãŸãƒ—ãƒ­ã®æ–‡ç« ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
           - å†—é•·ãªè¡¨ç¾ã¯é¿ã‘ã€æ ¸å¿ƒã‚’çªãã‚¹ãƒãƒ¼ãƒˆãªè¨˜è¿°ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
        
        prompt = [
            SystemMessage(content=system_prompt),
        ] + state["messages"] + [
            # æœ€å¾Œã«æ”¹ã‚ã¦ã€Œä¸»èªã‹ã‚‰å§‹ã‚ã‚ã€ã¨å¿µæŠ¼ã—ã™ã‚‹
            HumanMessage(content="ãã‚Œã§ã¯ã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚å¿…ãšä¸»èªã‹ã‚‰å§‹ã¾ã‚‹å®Œå…¨ãªæ–‡ç« ã§é–‹å§‹ã™ã‚‹ã“ã¨ã€‚")
        ]
        
        try:
            response = self.raw_model.invoke(prompt)
            
            logger.info(f"ğŸ” LLM Response length: {len(response.content)}")
            logger.info(f"ğŸ” LLM Response preview: {response.content[:200]}")
            
            # Extract matchup card data if present
            matchup_metadata = self._extract_matchup_data(state)
            
            final_result = {
                "final_answer": response.content,
                **matchup_metadata,  # Spread the dictionary
                "messages": [response]
            }
            
            logger.info(f"ğŸ” Final result keys: {final_result.keys()}")
            logger.info(f"ğŸ” final_answer length in result: {len(final_result.get('final_answer', ''))}")
            
            return final_result
        except Exception as e:
            raise AgentReasoningError("åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", original_error=e) from e
    
    def _extract_matchup_data(self, state):
        """Extract matchup card data from tool results"""
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—çµæœã‹ã‚‰å¯¾æˆ¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (UIã‚«ãƒ¼ãƒ‰ç”¨)

        # ui_metadata ã‚’åˆæœŸåŒ–
        ui_metadata = {
            "isMatchupCard": False,
            "matchupData": None
        }
    
        matchup_history = []
        matchup_stats = []
        
        for msg in state["messages"]:
            if isinstance(msg, ToolMessage):
                try:
                    data = json.loads(msg.content)
                    if isinstance(data, list) and len(data) > 0:
                        first_row = data[0]
                        # çƒç¨®åˆ¥åˆ†æãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        if "pitch_name" in first_row and ("batting_average" in first_row or "avg" in first_row):
                            # ã‚«ãƒ©ãƒ åã‚’çµ±ä¸€
                            for item in data:
                                if "avg" in item and "batting_average" not in item:
                                    item["batting_average"] = item["avg"]
                            matchup_stats = data
                            ui_metadata["isMatchupCard"] = True
                        # æ‰“å¸­å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        elif "game_date" in first_row:
                            matchup_history = data
                            ui_metadata["isMatchupCard"] = True
                except:
                    continue

        if ui_metadata["isMatchupCard"]:
            ui_metadata["matchupData"] = {
                "stats": matchup_stats,
                "history": matchup_history[:50], # æœ€æ–°50çƒåˆ†
                "summary": {
                    "batter": matchup_stats[0].get("batter_name") if matchup_stats else (matchup_history[0].get("batter_name") if matchup_history else "Batter"),
                    "pitcher": matchup_stats[0].get("pitcher_name") if matchup_stats else (matchup_history[0].get("pitcher_name") if matchup_history else "Pitcher"),
                }
            }
        
        return ui_metadata

    
    def run(self, query: str):
        """Execute matchup analysis"""
        from ..ai_agent_service import AgentState

        initial_state = {
            "messages": [HumanMessage(content=query)],
            "raw_data_store": {},
            "next_step": "",
            "final_answer": "",
            # Reflection Loop fields
            "retry_count": 0,
            "max_retries": 2,
            "last_error": None,
            "last_query_result_count": -1,
            "original_user_intent": query,
            # UI metadata
            "isTable": False,
            "isChart": False,
            "tableData": None,
            "chartData": None,
            "columns": None,
            "isTransposed": False,
            "chartType": "",
            "chartConfig": None,
            "isMatchupCard": False,
            "matchupData": None
        }
        
        result = self.graph.invoke(initial_state)
        
        # Extract only the fields needed by the API response
        return {
            "final_answer": result.get("final_answer", ""),
            "isTable": result.get("isTable", False),
            "isChart": result.get("isChart", False),
            "tableData": result.get("tableData", None),
            "chartData": result.get("chartData", None),
            "columns": result.get("columns", None),
            "isTransposed": result.get("isTransposed", False),
            "chartType": result.get("chartType", ""),
            "chartConfig": result.get("chartConfig", None),
            "isMatchupCard": result.get("isMatchupCard", False),
            "matchupData": result.get("matchupData", None),
            "raw_data_store": result.get("raw_data_store", {}),
            "next_step": "END"
        }
