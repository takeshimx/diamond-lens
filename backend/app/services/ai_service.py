from typing import Optional, List, Dict, Any
# from google.cloud import bigquery
# from google.oauth2 import service_account
from google.cloud.exceptions import GoogleCloudError
import pandas as pd
import os
import json
import requests
import re
from dotenv import load_dotenv
# from functools import lru_cache
from datetime import datetime
from .bigquery_service import client
import logging

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã¨æœ¬ç•ªå®Ÿè¡Œæ™‚ã®ä¸¡æ–¹ã«å¯¾å¿œ
try:
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from app.config.query_maps import (
        QUERY_TYPE_CONFIG,
        METRIC_MAP,
        DECIMAL_FORMAT_COLUMNS,
        MAIN_PITCHING_STATS,
        MAIN_BATTING_STATS,
        MAIN_CAREER_BATTING_STATS,
        MAIN_RISP_BATTING_STATS, MAIN_BASES_LOADED_BATTING_STATS, MAIN_RUNNER_ON_1B_BATTING_STATS,
        MAIN_INNING_BATTING_STATS, MAIN_BATTING_BY_PITCHING_THROWS_STATS, MAIN_BATTING_BY_PITCH_TYPE_STATS,
        MAIN_BATTING_BY_GAME_SCORE_SITUATIONS_STATS
    )
    from app.config.statcast_query import KEY_METRICS_QUERY_SELECT
except ImportError:
    # æœ¬ç•ªå®Ÿè¡Œæ™‚ã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from backend.app.config.query_maps import (
        QUERY_TYPE_CONFIG,
        METRIC_MAP,
        DECIMAL_FORMAT_COLUMNS,
        MAIN_PITCHING_STATS,
        MAIN_BATTING_STATS,
        MAIN_CAREER_BATTING_STATS,
        MAIN_RISP_BATTING_STATS, MAIN_BASES_LOADED_BATTING_STATS, MAIN_RUNNER_ON_1B_BATTING_STATS,
        MAIN_INNING_BATTING_STATS, MAIN_BATTING_BY_PITCHING_THROWS_STATS, MAIN_BATTING_BY_PITCH_TYPE_STATS,
        MAIN_BATTING_BY_GAME_SCORE_SITUATIONS_STATS
    )
    from backend.app.config.statcast_query import KEY_METRICS_QUERY_SELECT
# from .simple_chart_service import enhance_response_with_simple_chart, should_show_simple_chart # For Development, add backend. path

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.getLogger().handlers = []
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

dotenv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '.env')
load_dotenv(dotenv_path=dotenv_path)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€
PROJECT_ID = os.getenv("GCP_PROJECT_ID")
DATASET_ID = os.getenv("BIGQUERY_DATASET_ID")
BATTING_STATS_TABLE_ID = os.getenv("BIGQUERY_BATTING_STATS_TABLE_ID", "fact_batting_stats_with_risp")
PITCHING_STATS_TABLE_ID = os.getenv("BIGQUERY_PITCHING_STATS_TABLE_ID", "fact_pitching_stats")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_V2")

# Manage Google cloud alient with singleton pattern
SERVICE_ACCOUNT_KEY_PATH = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")


def _parse_query_with_llm(query: str, season: Optional[int]) -> Optional[Dict[str, Any]]:
    """
    [ã‚¹ãƒ†ãƒƒãƒ—1] LLMã‚’ä½¿ã„ã€è³ªå•ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯LLMã®å½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è§£æã—ã€ã€Œæ„å›³ã€ã‚’æ±²ã¿å–ã‚Šã€
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¾ã™ã€‚
    """
    if not GEMINI_API_KEY:
        logger.error("GEMINI_API_KEY_V2 is not set.")
        return None

    prompt = f"""
    ã‚ãªãŸã¯MLBã®ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®"æ‰“æ’ƒæˆç¸¾ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°"ã€"æŠ•æ‰‹æˆç¸¾ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°"ã€ã¾ãŸã¯"é¸æ‰‹æˆç¸¾"ã«é–¢ã™ã‚‹ä»¥ä¸‹ã®è³ªå•ã‚’è§£æã—ã€
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

    # æŒ‡ç¤º
    - é¸æ‰‹åã¯è‹±èªè¡¨è¨˜ï¼ˆãƒ•ãƒ«ãƒãƒ¼ãƒ ï¼‰ã«æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼šã€Œå¤§è°·ã•ã‚“ã€ -> "Shohei Ohtani"
    - `season`ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰å¹´ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚`season`ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã¾ãŸã¯ã€Œã‚­ãƒ£ãƒªã‚¢ã€ã‚„ã€Œé€šç®—ã€ãªã©ã®è¡¨ç¾ãŒã‚ã‚Œã°ã€`season`ã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - `query_type`ã¯ "season_batting"ã€"season_pitching"ã€ "batting_splits"ã€ã¾ãŸã¯ "career_batting" ã®ã„ãšã‚Œã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
    - `metrics`ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒçŸ¥ã‚ŠãŸã„æŒ‡æ¨™ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§æ ¼ç´ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€ãƒ›ãƒ¼ãƒ ãƒ©ãƒ³æ•°ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã¯ ["homerun"] ã¨ã—ã¾ã™ã€‚æ‰“ç‡ã®å ´åˆã¯ ["batting_average"] ã¨ã—ã€å˜èªã¨å˜èªã®é–“ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    - `split_type`ã¯ã€ã€Œå¾—ç‚¹åœï¼ˆRISPï¼‰ã€ã€Œæº€å¡ã€ã€Œãƒ©ãƒ³ãƒŠãƒ¼1é¡ã€ã€Œã‚¤ãƒ‹ãƒ³ã‚°åˆ¥ã€ã€ŒæŠ•æ‰‹ãŒå·¦æŠ•ã’ã‹å³æŠ•ã’ã‹ã€ã€Œçƒç¨®åˆ¥ã€ã€Œã‚²ãƒ¼ãƒ ã‚¹ã‚³ã‚¢çŠ¶æ³åˆ¥ã€ãªã©ã®ç‰¹å®šã®çŠ¶æ³ã‚’ç¤ºã—ã¾ã™ã€‚è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - `split_type`ã§ã€game_score_situation (ã‚²ãƒ¼ãƒ ã‚¹ã‚³ã‚¢çŠ¶æ³åˆ¥) ã‚’é¸æŠã—ãŸå ´åˆã€`game_score`ã«å…·ä½“çš„ãªã‚¹ã‚³ã‚¢çŠ¶æ³ï¼ˆä¾‹ï¼š1ç‚¹ãƒªãƒ¼ãƒ‰ã€2ç‚¹ãƒ“ãƒã‚¤ãƒ³ãƒ‰ãªã©ï¼‰ã‚’ç¤ºã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
        ä¾‹ãˆã°ã€ã€Œ1ç‚¹å·®ã‚²ãƒ¼ãƒ ã€1ç‚¹ãƒªãƒ¼ãƒ‰ã€1ç‚¹ãƒ“ãƒã‚¤ãƒ³ãƒ‰ã€ã¯ã€'one_run_game'ã€'one_run_lead'ã€'one_run_trail'ã®ã‚ˆã†ã«è¡¨ç¾ã—ã¾ã™ã€‚4ç‚¹ä»¥ä¸Šã®å·®ã¯'four_plus_run_lead'ã‚„'four_plus_run_trail'ã¨ã—ã¦ãã ã•ã„ã€‚è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - `split_type`ã§ã€inning (ã‚¤ãƒ‹ãƒ³ã‚°åˆ¥) ã‚’é¸æŠã—ãŸå ´åˆã€`inning`ã«å…·ä½“çš„ãªã‚¤ãƒ‹ãƒ³ã‚°æ•°ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ç¤ºã—ã¦ãã ã•ã„ã€‚ãƒ¬ã‚®ãƒ¥ãƒ©ãƒ¼ã‚¤ãƒ‹ãƒ³ã‚°æ•°ã¯1~9ã‚¤ãƒ‹ãƒ³ã‚°ã¾ã§ã€‚ä¾‹ï¼š1ã‚¤ãƒ‹ãƒ³ã‚°ç›®ãªã‚‰ [1]ã€7ã‚¤ãƒ‹ãƒ³ã‚°ç›®ä»¥é™ãªã‚‰ [7, 8, 9] ã¨ã—ã¾ã™ã€‚
    - `strikes`ã¯ã€ç‰¹å®šã®ã‚¹ãƒˆãƒ©ã‚¤ã‚¯æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚`balls`ã¯ã€ç‰¹å®šã®ãƒœãƒ¼ãƒ«æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - ä¾‹ãˆã°ã€ã€Œãƒ•ãƒ«ã‚«ã‚¦ãƒ³ãƒˆã€ã¯ã€ `strikes`ã‚’2ã€`balls`ã‚’3ã¨ã—ã¦ãã ã•ã„ã€‚ã€Œåˆçƒã€ã¯ã€`strikes`ã‚’0ã€`balls`ã‚’0ã¨ã—ã¾ã™ã€‚è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - `pitcher_throws`ã¯ã€æŠ•æ‰‹ã®æŠ•ã’æ–¹ï¼ˆå³æŠ•ã’ã¾ãŸã¯å·¦æŠ•ã’ï¼‰ã‚’ç¤ºã—ã¾ã™ã€‚å³æŠ•ã’ã¯RHPã€å·¦æŠ•ã’ã¯LHPã¨ã—ã€è©²å½“ã—ãªã„å ´åˆã¯nullã«ã—ã¦ãã ã•ã„ã€‚
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã€ã‚„ã€Œä¸»ãªæˆç¸¾ã€ã®ã‚ˆã†ãªæ›–æ˜§ãªè¡¨ç¾ã‚’ä½¿ã£ãŸå ´åˆã€metricsã«ã¯ ["main_stats"] ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¸€ã¤ã ã‘æ ¼ç´ã—ã¦ãã ã•ã„ã€‚
    - `order_by`ã«ã¯ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®åŸºæº–ã¨ãªã‚‹æŒ‡æ¨™ã‚’ä¸€ã¤ã ã‘è¨­å®šã—ã¦ãã ã•ã„ã€‚
    - `output_format`ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ "sentence" ã§ã™ã€‚ã‚‚ã—ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã€è¡¨ã§ã€ã€ä¸€è¦§ã§ã€ã€ã¾ã¨ã‚ã¦ã€ã¨ã„ã£ãŸã‚ˆã†ãªè¨€è‘‰ãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰ã€output_formatã‚’tableã«è¨­å®šã—ã¦ãã ã•ã„ã€‚ãã†ã§ãªã‘ã‚Œã°sentenceã«ã—ã¦ãã ã•ã„ã€‚

    # JSONã‚¹ã‚­ãƒ¼ãƒ
    {{
        "query_type": "season_batting" | "season_pitching" | "batting_splits" | "career_batting" | null,
        "metrics": ["string"],
        "split_type": "risp" | "bases_loaded" | "runner_on_1b" | "inning" | "pitcher_throws" | "pitch_type" | "game_score_situation" | "monthly" | null,
        "inning": ["integer"] | null,
        "strikes": "integer | null",
        "balls": "integer | null",
        "game_score": "string | null",
        "pitcher_throws": "string | null",
        "pitch_type": ["string"] | null,
        "name": "string | null",
        "season": "integer | null",
        "order_by": "string",
        "limit": "integer | null",
        "output_format": "sentence" | "table"
    }}

    # è³ªå•ã®ä¾‹
    è³ªå•: ã€Œ2023å¹´ã®ãƒ›ãƒ¼ãƒ ãƒ©ãƒ³ç‹ã¯èª°ï¼Ÿã€
    JSON: {{ "query_type": "season_batting", "season": 2023, "metrics": ["homerun"],  "order_by": "homerun", "limit": 1 }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®RISPæ™‚ã®ä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã¯ï¼Ÿã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["main_stats"], "split_type": "risp", "order_by": null, "limit": 1 }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®ã®2024å¹´ã®1ã‚¤ãƒ‹ãƒ³ã‚°ç›®ã®ãƒ›ãƒ¼ãƒ ãƒ©ãƒ³æ•°ã¨OPSã‚’æ•™ãˆã¦ã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["homerun", "on_base_plus_slugging"], "split_type": "inning", "inning": 1, "order_by": null, "limit": 1 }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®å·¦æŠ•æ‰‹ã«å¯¾ã™ã‚‹ä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã‚’ä¸€è¦§ã§æ•™ãˆã¦ï¼Ÿã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["main_stats"], "split_type": "pitcher_throws", "pitcher_throws": "LHP", "order_by": null, "limit": 1, "output_format": "table" }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã«å¯¾ã™ã‚‹ä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã¯ï¼Ÿã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["main_stats"], "split_type": "pitch_type", "pitch_type": "Slider", "order_by": null }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®ã‚­ãƒ£ãƒªã‚¢ä¸»è¦æ‰“æ’ƒæˆç¸¾ã‚’ä¸€è¦§ã§æ•™ãˆã¦ã€
    JSON: {{ "query_type": "career_batting", "name": "Shohei Ohtani", "metrics": ["main_stats"], "order_by": null, "limit": 1, "output_format": "table" }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®ã€1ç‚¹ãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã®ä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã¯ï¼Ÿã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["main_stats"], "split_type": "game_score_situation", "game_score": "one_run_trail", "order_by": null, "limit": 1 }}

    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®æ‰“ç‡ã‚’æœˆæ¯ã®æ¨ç§»ã‚’ãƒãƒ£ãƒ¼ãƒˆã§æ•™ãˆã¦ã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["batting_average"], "split_type": "monthly", "order_by": null }}

    # è¤‡åˆè³ªå•ã®ä¾‹
    è³ªå•: ã€Œå¤§è°·ã•ã‚“ã®2024å¹´ã®7ã‚¤ãƒ‹ãƒ³ã‚°ç›®ä»¥é™ã€ãƒ•ãƒ«ã‚«ã‚¦ãƒ³ãƒˆã§ã®ã€RISPæ™‚ã®ä¸»è¦ã‚¹ã‚¿ãƒƒãƒ„ã¯ï¼Ÿã€
    JSON: {{ "query_type": "batting_splits", "name": "Shohei Ohtani", "season": 2024,  "metrics": ["main_stats"], "split_type": "risp", "inning": [7, 8, 9], "strikes": 2, "balls": 3, "order_by": null, "limit": 1 }}

    # æœ¬ç•ª
    è³ªå•: ã€Œ{query}ã€
    JSON:
    """

    GEMINI_API_URL=f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"responseMimeType": "application/json"}
    }

    try:
        response = requests.post(GEMINI_API_URL, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()
        if result.get("candidates"):
            json_string = result["candidates"][0]["content"]["parts"][0]["text"]
            params = json.loads(json_string)

            logger.info(f"Parsed parameters: {params}")

            if season and 'season' not in params:
                params['season'] = season
            return params
        return None
    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:
        logger.error(f"Error during LLM query parsing: {e}", exc_info=True)
        return None


def _validate_query_params(params: Dict[str, Any]) -> bool:
    """
    LLMå‡ºåŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ã‚’è¡Œã„ã¾ã™ã€‚
    SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã‚„ãã®ä»–ã®ä¸æ­£ãªå…¥åŠ›ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

    Args:
        params: LLMã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        bool: æ¤œè¨¼ã«åˆæ ¼ã—ãŸå ´åˆTrueã€ä¸æ­£ãªå…¥åŠ›ã‚’æ¤œå‡ºã—ãŸå ´åˆFalse

    æ¤œè¨¼é …ç›®:
        1. é¸æ‰‹å: è‹±å­—ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ãƒ”ãƒªã‚ªãƒ‰ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ã®ã¿è¨±å¯
        2. Season: å¦¥å½“ãªå¹´ã®ç¯„å›²ï¼ˆ1900-2100ï¼‰
        3. query_type: ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹å€¤ã®ã¿
        4. split_type: ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹å€¤ã®ã¿
        5. metrics: METRIC_MAPã«å«ã¾ã‚Œã‚‹å€¤ã®ã¿ï¼ˆmain_statsã‚’é™¤ãï¼‰
        6. order_by: METRIC_MAPã«å«ã¾ã‚Œã‚‹å€¤ã®ã¿
        7. pitcher_throws: RHPã¾ãŸã¯LHPã®ã¿
        8. inning: 1-9ã®æ•´æ•°ã®ã¿
        9. strikes/balls: 0-3ã®æ•´æ•°ã®ã¿
        10. é•·ã•åˆ¶é™: ç•°å¸¸ã«é•·ã„æ–‡å­—åˆ—ã‚’æ‹’å¦
    """

    # 1. é¸æ‰‹åã®æ¤œè¨¼
    if params.get("name"):
        name = params["name"]

        # è‹±å­—ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ãƒ”ãƒªã‚ªãƒ‰ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ã®ã¿è¨±å¯
        # ä¾‹: "Shohei Ohtani", "Mike O'Malley", "Jose Martinez Jr."
        if not re.match(r"^[A-Za-z\s\.\-']+$", name):
            logger.warning(f"âš ï¸ Invalid name format detected: {name}")
            return False

        # é•·ã•åˆ¶é™ï¼ˆ100æ–‡å­—ä»¥ä¸Šã¯ç•°å¸¸ï¼‰
        if len(name) > 100:
            logger.warning(f"âš ï¸ Name too long: {len(name)} characters")
            return False

        # SQLã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡ºï¼ˆåŸºæœ¬çš„ãªæ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        sql_keywords = [
            'SELECT', 'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE',
            'ALTER', 'UNION', 'WHERE', 'OR', 'AND', '--', '/*', '*/',
            'EXEC', 'EXECUTE', 'SCRIPT', 'JAVASCRIPT', 'EVAL'
        ]
        name_upper = name.upper()
        for keyword in sql_keywords:
            if keyword in name_upper:
                logger.warning(f"âš ï¸ SQL keyword detected in name: {name}")
                return False

    # 2. Seasonã®æ¤œè¨¼
    if params.get("season") is not None:
        season = params["season"]

        # æ•´æ•°å‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(season, int):
            logger.warning(f"âš ï¸ Season must be integer: {season}")
            return False

        # å¦¥å½“ãªå¹´ã®ç¯„å›²
        if not (1900 <= season <= 2100):
            logger.warning(f"âš ï¸ Invalid season range: {season}")
            return False

    # 3. query_typeã®æ¤œè¨¼ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼‰
    if params.get("query_type"):
        valid_query_types = ["season_batting", "season_pitching", "batting_splits", "career_batting"]
        if params["query_type"] not in valid_query_types:
            logger.warning(f"âš ï¸ Invalid query_type: {params['query_type']}")
            return False

    # 4. split_typeã®æ¤œè¨¼ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼‰
    if params.get("split_type"):
        valid_split_types = [
            "risp", "bases_loaded", "runner_on_1b", "inning",
            "pitcher_throws", "pitch_type", "game_score_situation", "monthly"
        ]
        if params["split_type"] not in valid_split_types:
            logger.warning(f"âš ï¸ Invalid split_type: {params['split_type']}")
            return False

    # 5. metricsã®æ¤œè¨¼
    if params.get("metrics"):
        metrics = params["metrics"]

        # ãƒªã‚¹ãƒˆå‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(metrics, list):
            logger.warning(f"âš ï¸ Metrics must be list: {metrics}")
            return False

        # "main_stats"ã¯ç‰¹æ®Šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã®ã§è¨±å¯
        if metrics != ["main_stats"]:
            # å„ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒMETRIC_MAPã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for metric in metrics:
                if metric not in METRIC_MAP and metric != "main_stats":
                    logger.warning(f"âš ï¸ Invalid metric: {metric}")
                    return False

    # 6. order_byã®æ¤œè¨¼
    if params.get("order_by"):
        order_by = params["order_by"]

        # METRIC_MAPã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if order_by not in METRIC_MAP:
            logger.warning(f"âš ï¸ Invalid order_by: {order_by}")
            return False

    # 7. pitcher_throwsã®æ¤œè¨¼
    if params.get("pitcher_throws"):
        pitcher_throws = params["pitcher_throws"]

        # RHPã¾ãŸã¯LHPã®ã¿è¨±å¯
        if pitcher_throws not in ["RHP", "LHP"]:
            logger.warning(f"âš ï¸ Invalid pitcher_throws: {pitcher_throws}")
            return False

    # 8. inningã®æ¤œè¨¼
    if params.get("inning") is not None:
        inning = params["inning"]

        # ãƒªã‚¹ãƒˆã¾ãŸã¯æ•´æ•°
        if isinstance(inning, list):
            for inn in inning:
                if not isinstance(inn, int) or not (1 <= inn <= 9):
                    logger.warning(f"âš ï¸ Invalid inning in list: {inn}")
                    return False
        elif isinstance(inning, int):
            if not (1 <= inning <= 9):
                logger.warning(f"âš ï¸ Invalid inning: {inning}")
                return False
        else:
            logger.warning(f"âš ï¸ Inning must be int or list: {inning}")
            return False

    # 9. strikes/ballsã®æ¤œè¨¼
    if params.get("strikes") is not None:
        strikes = params["strikes"]
        if not isinstance(strikes, int) or not (0 <= strikes <= 3):
            logger.warning(f"âš ï¸ Invalid strikes: {strikes}")
            return False

    if params.get("balls") is not None:
        balls = params["balls"]
        if not isinstance(balls, int) or not (0 <= balls <= 3):
            logger.warning(f"âš ï¸ Invalid balls: {balls}")
            return False

    # 10. pitch_typeã®æ¤œè¨¼
    if params.get("pitch_type"):
        pitch_types = params["pitch_type"]

        # ãƒªã‚¹ãƒˆå‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(pitch_types, list):
            logger.warning(f"âš ï¸ pitch_type must be list: {pitch_types}")
            return False

        # å„çƒç¨®ãŒå¦¥å½“ãªæ–‡å­—åˆ—ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆè‹±å­—ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ãƒã‚¤ãƒ•ãƒ³ã®ã¿ï¼‰
        for pt in pitch_types:
            if not isinstance(pt, str) or not re.match(r"^[A-Za-z\s\-]+$", pt):
                logger.warning(f"âš ï¸ Invalid pitch_type: {pt}")
                return False

            # é•·ã•åˆ¶é™
            if len(pt) > 50:
                logger.warning(f"âš ï¸ pitch_type too long: {pt}")
                return False

    # 11. game_scoreã®æ¤œè¨¼
    if params.get("game_score"):
        valid_game_scores = [
            'one_run_game', 'one_run_lead', 'one_run_trail',
            'two_run_game', 'two_run_lead', 'two_run_trail',
            'three_run_game', 'three_run_lead', 'three_run_trail',
            'four_plus_run_game', 'four_plus_run_lead', 'four_plus_run_trail',
            'tie_game'
        ]
        if params["game_score"] not in valid_game_scores:
            logger.warning(f"âš ï¸ Invalid game_score: {params['game_score']}")
            return False

    # 12. limitã®æ¤œè¨¼
    if params.get("limit") is not None:
        limit = params["limit"]

        # æ•´æ•°å‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(limit, int):
            logger.warning(f"âš ï¸ limit must be integer: {limit}")
            return False

        # å¦¥å½“ãªç¯„å›²ï¼ˆ1-1000ï¼‰
        if not (1 <= limit <= 1000):
            logger.warning(f"âš ï¸ Invalid limit range: {limit}")
            return False

    # 13. output_formatã®æ¤œè¨¼
    if params.get("output_format"):
        if params["output_format"] not in ["sentence", "table"]:
            logger.warning(f"âš ï¸ Invalid output_format: {params['output_format']}")
            return False

    logger.info("âœ… Query parameters validation passed")
    return True


# Helper function to determine query strategy (using a simple query or more complex one)
def _determine_query_strategy(params: Dict[str, Any]) -> str:
    """
    ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«åŸºã¥ã„ã¦æˆ¦ç•¥ã‚’æ±ºå®šã™ã‚‹
    - è¤‡åˆæ¡ä»¶ãŒ2ã¤ä»¥ä¸Š: statcast master table
    - å˜ä¸€æ¡ä»¶: aggregated table
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ãŒå¿…è¦ãªå ´åˆã®ç‰¹åˆ¥å‡¦ç†ã‚‚å«ã‚€
    """

    complex_conditions = []

    # ã‚¤ãƒ‹ãƒ³ã‚°æ¡ä»¶
    if params.get("inning"):
        complex_conditions.append("inning")
    
    # ã‚«ã‚¦ãƒ³ãƒˆæ¡ä»¶
    if params.get("strikes") is not None:
        complex_conditions.append("strikes")
    if params.get("balls") is not None:
        complex_conditions.append("balls")
    
    # æŠ•æ‰‹ã‚¿ã‚¤ãƒ—æ¡ä»¶
    if params.get("pitcher_throws"):
        complex_conditions.append("pitcher_throws")
    
    # çƒç¨®æ¡ä»¶
    if params.get("pitch_type"):
        complex_conditions.append("pitch_type")
    
    # çŠ¶æ³æ¡ä»¶
    situational_splits = ["risp", "bases_loaded", "runner_on_1b"]
    if params.get("split_type") in situational_splits:
        complex_conditions.append("situational")
    
    # ã‚²ãƒ¼ãƒ ã‚¹ã‚³ã‚¢çŠ¶æ³æ¡ä»¶
    if params.get("game_score"):
        complex_conditions.append("game_score")
    
    # è¤‡åˆæ¡ä»¶ã®åˆ¤å®š
    condition_count = len(complex_conditions)

    # ç‰¹åˆ¥ãªã‚±ãƒ¼ã‚¹ï¼šè¤‡æ•°å¹´ãƒ‡ãƒ¼ã‚¿ + è¤‡åˆæ¡ä»¶ã¯é‡ã™ãã‚‹å¯èƒ½æ€§
    if not params.get("season") and condition_count >= 2:
        logger.warning(f"Multi-year query with {condition_count} complex conditions may be slow")

    strategy = "statcast_master_table" if condition_count >= 2 else "aggregated_table"

    logger.info(f"Query strategy: {strategy} based on condition count: {condition_count}")
    return strategy


# Helper function to build dynamic SQL queries with statcast_master_table
def _build_dynamic_statcast_sql(params: Dict[str, Any]) -> tuple[str, dict]:
    """
    statcast_master_tableã«å¯¾ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

    Args:
        params: LLMã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        tuple[str, dict]: (SQLæ–‡å­—åˆ—, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸)
    """

    metrics = params.get("metrics", [])
    if not metrics:
        return None, {}
    
    # Replace keyword from "main_stats" with related column list
    if metrics == ["main_stats"]:
        metrics = MAIN_BATTING_STATS # tentative
    
    table_name = "tbl_statcast_2021_2025_master"
    year_column = "game_year"
    player_name_col = "batter_name"

    
    # static query part
    # SELECT clause
    # if all seasons
    if not params.get("season"):
        select_clause = KEY_METRICS_QUERY_SELECT
    else:
        select_clause = KEY_METRICS_QUERY_SELECT + ", game_year"

    # dynamic query part - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
    # WHERE clause
    where_conditions = []
    query_parameters = {}

    if params.get("name"):
        where_conditions.append(f"{player_name_col} = @player_name")
        query_parameters["player_name"] = params["name"]

    if params.get("season"):
        where_conditions.append(f"{year_column} = @season")
        query_parameters["season"] = params["season"]

    if params.get("inning"):
        innings = params['inning']
        if isinstance(innings, list):
            where_conditions.append(f"inning IN UNNEST(@innings)")
            query_parameters["innings"] = innings
        else:
            where_conditions.append(f"inning = @inning")
            query_parameters["inning"] = innings

    if params.get('pitcher_throws'):
        where_conditions.append(f"p_throws = @pitcher_throws")
        query_parameters["pitcher_throws"] = params['pitcher_throws']

    if params.get("strikes") is not None:
        where_conditions.append(f"strikes = @strikes")
        query_parameters["strikes"] = params["strikes"]

    if params.get("balls") is not None:
        where_conditions.append(f"balls = @balls")
        query_parameters["balls"] = params["balls"]

    if params.get('split_type'):
        if params['split_type'] == 'risp':
            where_conditions.append("(on_2b != 0 OR on_3b != 0)")
        elif params['split_type'] == 'bases_loaded':
            where_conditions.append("(on_1b != 0 AND on_2b != 0 AND on_3b != 0)")
        elif params['split_type'] == 'runner_on_1b':
            where_conditions.append("(on_1b != 0 AND on_2b = 0 AND on_3b = 0)")

    where_clause = f"WHERE events IS NOT NULL AND game_type = 'R'"
    if where_conditions:
        where_clause += f" AND {' AND '.join(where_conditions)}"

    # GROUP BY clause # all seasons can be selected, to be updated
    if params.get("season"):
        group_by_clause = f"GROUP BY {year_column}, {player_name_col}"
    else:
        group_by_clause = f"GROUP BY {player_name_col}"

    # ORDER BY clause # To be implemented later
    order_by_clause = ""

    # LIMIT clause - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–
    limit_clause = ""
    if params.get("limit") is not None:
        limit_clause = f"LIMIT @limit"
        query_parameters["limit"] = params["limit"]

    query_string = f"{select_clause} FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` {where_clause} {group_by_clause} {order_by_clause} {limit_clause}"

    logger.info(f"âœ… Built parameterized statcast query with {len(query_parameters)} parameters")
    return query_string, query_parameters
        
 

# Helper function to build dynamic SQL queries with aggregated table
def _build_dynamic_sql(params: Dict[str, Any]) -> tuple[str, dict]:
    """
    [ã‚¹ãƒ†ãƒƒãƒ—2] æŠ½å‡ºã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…ƒã«ã€BigQueryç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

    Args:
        params: LLMã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        tuple[str, dict]: (SQLæ–‡å­—åˆ—, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸)
        - SQLæ–‡å­—åˆ—: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆ@param_nameï¼‰ã‚’å«ã‚€ã‚¯ã‚¨ãƒª
        - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«å¯¾å¿œã™ã‚‹å®Ÿéš›ã®å€¤
    """

    # Without query_type and metrics, a query can not be constructed
    query_type = params.get("query_type", [])
    metrics = params.get("metrics", []) # multiple metrics could be stored in the dictionary
    if not query_type or not metrics:
        return None, {}
    
    split_type = params.get("split_type", [])
    
    # Replace keyword from "main_stats" with related column list
    if metrics == ["main_stats"]:
        if query_type == "season_pitching":
            metrics = MAIN_PITCHING_STATS
        elif query_type == "season_batting":
            metrics = MAIN_BATTING_STATS
        elif query_type == "career_batting":
            metrics = MAIN_CAREER_BATTING_STATS
        elif query_type == "batting_splits" and split_type == "risp":
            metrics = MAIN_RISP_BATTING_STATS
        elif query_type == "batting_splits" and split_type == "bases_loaded":
            metrics = MAIN_BASES_LOADED_BATTING_STATS
        elif query_type == "batting_splits" and split_type == "runner_on_1b":
            metrics = MAIN_RUNNER_ON_1B_BATTING_STATS
        elif query_type == "batting_splits" and split_type == "inning":
            metrics = MAIN_INNING_BATTING_STATS
        elif query_type == "batting_splits" and split_type == "pitcher_throws":
            metrics = MAIN_BATTING_BY_PITCHING_THROWS_STATS
        elif query_type == "batting_splits" and split_type == "pitch_type":
            metrics = MAIN_BATTING_BY_PITCH_TYPE_STATS
        elif query_type == "batting_splits" and split_type == "game_score_situation":
            metrics = MAIN_BATTING_BY_GAME_SCORE_SITUATIONS_STATS
        # Add another metrics if needed from here

    # Initialize variables
    config = None
    metric_map_key_base = query_type  # Default key for METRIC_MAP

    # Get config info
    if query_type in ["season_batting", "season_pitching", "career_batting"]:
        config = QUERY_TYPE_CONFIG.get(query_type)
    elif query_type == "batting_splits" and params.get("split_type"):
        split_type = params.get("split_type")
        config = QUERY_TYPE_CONFIG.get(query_type, {}).get(split_type)
        metric_map_key_base = f"{query_type}_{split_type}"

    if not config:
        logger.error(f"Configuration not found for query_type: {query_type}")
        return None, {}
    
    table_name = config["table_id"]
    year_column = config["year_col"]
    month_column = config.get("month_col", None)
    player_name_col = config["player_col"]
    # default_colsã‚’å‹•çš„ã«è¨­å®š
    if query_type == "career_batting":
        default_cols = [f"{player_name_col} as name", "career_last_team"]
    elif split_type == "monthly" and month_column:
        default_cols = [f"{player_name_col} as name", f"{month_column} as month"]
    else:
        default_cols = [f"{player_name_col} as name", f"{year_column} as season"]
    if "team" in config.get("available_metrics", []) or config.get("table_id") in [BATTING_STATS_TABLE_ID, PITCHING_STATS_TABLE_ID]:
        if "team" not in default_cols:
            default_cols.insert(1, "team")

    # METRIC_MAPã‹ã‚‰å®‰å…¨ã«å€¤ã‚’å–å¾—ã—ã€Noneã‚’é™¤å¤–
    if query_type == "career_batting":
        queried_metrics = []
        # Group by context first (career, risp, bases_loaded), then by metric type
        for key in ["career", "risp", "bases_loaded"]:
            for metric in metrics:
                metric_mapping = METRIC_MAP.get(metric, {}).get(metric_map_key_base, {}).get(key)
                if metric_mapping:
                    queried_metrics.append(metric_mapping)
    else:
        queried_metrics = [METRIC_MAP.get(metric, {}).get(metric_map_key_base) for metric in metrics]
    # Debugging
    logger.debug(f"Queried metrics for {query_type}: {queried_metrics}")
    # NoneãŒãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹ã¨SQLæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ã€ã“ã“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    valid_queried_metrics = [m for m in queried_metrics if m is not None]

    # SELECT clause
    if split_type == "pitch_type":
        select_cols = default_cols + ["pitch_name"] + [m for m in valid_queried_metrics if m not in ['name', 'team', 'season']]
    else:
        select_cols = default_cols + [m for m in valid_queried_metrics if m not in ['name', 'team', 'season']]
    # Deduplicate
    final_select_cols = list(dict.fromkeys(select_cols))
    select_clause = f"SELECT {', '.join(final_select_cols)}"

    # WHERE clause - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
    where_conditions = []
    query_parameters = {}

    if params.get("name"):
        where_conditions.append(f"{player_name_col} = @player_name")
        query_parameters["player_name"] = params["name"]

    if params.get("season"):
        where_conditions.append(f"{year_column} = @season")
        query_parameters["season"] = params["season"]

    if params.get("inning") is not None and split_type == "inning":
        where_conditions.append(f"inning = @inning")
        query_parameters["inning"] = params["inning"]

    if params.get("pitcher_throws") and split_type == "pitcher_throws":
        where_conditions.append(f"p_throws = @pitcher_throws")
        query_parameters["pitcher_throws"] = params["pitcher_throws"]

    if params.get("pitch_type") and split_type == "pitch_type":
        # BigQueryã®é…åˆ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦INå¥ã‚’å®‰å…¨ã«æ§‹ç¯‰
        where_conditions.append(f"pitch_name IN UNNEST(@pitch_types)")
        query_parameters["pitch_types"] = params["pitch_type"]

    where_clause = f"WHERE {' AND '.join(where_conditions)}" if where_conditions else ""

    # GROUP BY clause
    group_by_clause = ""
    if params.get("pitch_type") and split_type == "pitch_type" and len(params['pitch_type']) > 1:
        group_by_clause = f"GROUP BY {', '.join([player_name_col, year_column, 'pitch_name'] + [m for m in valid_queried_metrics if m not in ['name', 'team', 'season']])}"

    # ORDER BY clause - ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆæ–¹å¼ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ä¸å¯ï¼‰
    order_by_clause = ""
    if params.get("order_by"):
        # METRIC_MAPã«å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ä½¿ç”¨ï¼ˆ_validate_query_paramsã§æ¤œè¨¼æ¸ˆã¿ï¼‰
        order_by_col = METRIC_MAP.get(params["order_by"], {}).get(metric_map_key_base)
        if order_by_col:
            order_direction = "ASC" if order_by_col in ("era", "whip", "fip") else "DESC"
            order_by_clause = f"ORDER BY {order_by_col} {order_direction}"
    elif split_type == "monthly" and month_column:
        order_by_clause = f"ORDER BY {month_column} ASC"

    # LIMIT clause - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–
    limit_clause = ""
    if params.get("limit") is not None:
        limit_clause = f"LIMIT @limit"
        query_parameters["limit"] = params["limit"]

    query_string = f"{select_clause} FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` {where_clause} {group_by_clause} {order_by_clause} {limit_clause}"

    logger.info(f"âœ… Built parameterized query with {len(query_parameters)} parameters")
    return query_string, query_parameters


def _generate_final_response_with_llm(original_query: str, data_df: pd.DataFrame) -> str:
    """
    [ã‚¹ãƒ†ãƒƒãƒ—4] å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨å…ƒã®è³ªå•ã«åŸºã¥ã„ã¦ã€LLMãŒè‡ªç„¶è¨€èªã®å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    * ã‚¹ãƒ†ãƒƒãƒ—3ã¯BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã™ã€‚
    """
    if not GEMINI_API_KEY:
        logger.error("GEMINI_API_KEY_V2 is not set.")
        return "AIã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    data_json_str = data_df.to_json(orient='records', indent=2, force_ascii=False)
    prompt = f"""
    ã‚ãªãŸã¯MLBã®ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç°¡æ½”ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãƒ‡ãƒ¼ã‚¿ã¯è¡¨å½¢å¼ã§æç¤ºã™ã‚‹ã®ã§ã¯ãªãã€è‡ªç„¶ãªæ–‡ç« ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

    ---
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {original_query}
    æä¾›ãƒ‡ãƒ¼ã‚¿ (JSONå½¢å¼):
    {data_json_str}
    ---
    å›ç­”:
    """
    GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {"contents": [{"parts": [{"text": prompt}]}]}

    try:
        response = requests.post(GEMINI_API_URL, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()
        if result.get("candidates"):
            generated_text = result["candidates"][0]["content"]["parts"][0]["text"]
            return generated_text.replace('\n', '<br>')
        return "AIã«ã‚ˆã‚‹å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except requests.exceptions.RequestException as e:
        logger.error(f"Error calling Gemini API for final response: {e}", exc_info=True)
        return "AIã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"


def get_ai_response_for_qna_enhanced(query: str, season: Optional[int] = None) -> Optional[Dict[str, Any]]:
    """
    ã€æ‰“æ’ƒãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ç‰¹åŒ–ç‰ˆã€‘
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®"æ‰“æ’ƒãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰"ã«é–¢ã™ã‚‹è³ªå•ã‚’å‡¦ç†ã—ã¾ã™ã€‚
    """
    # Step 1: LLMã§è³ªå•ã‚’è§£æ
    query_params = _parse_query_with_llm(query, season)
    if not query_params:
        logger.warning("Could not extract parameters from the query.")
        return {
            "answer": "è³ªå•ã‚’ç†è§£ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ‰“æ’ƒæˆç¸¾ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼š2024å¹´ã®ãƒ›ãƒ¼ãƒ ãƒ©ãƒ³ç‹ã¯èª°ï¼Ÿï¼‰",
            "isTable": False
        }
    logger.info(f"Parsed query parameters: {query_params}")

    # Step 1.5: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ï¼ˆSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
    if not _validate_query_params(query_params):
        logger.error(f"Security validation failed for parameters: {query_params}")
        return {
            "answer": "ä¸æ­£ãªå…¥åŠ›ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚æ­£ã—ã„å½¢å¼ã§è³ªå•ã—ã¦ãã ã•ã„ã€‚",
            "isTable": False
        }

    # Step 2: Build SQL with parameterization
    query_strategy = _determine_query_strategy(query_params)
    logger.info(f"Using query strategy: {query_strategy}")

    if query_strategy == "aggregated_table":
        # Using aggregated table
        sql_query, sql_parameters = _build_dynamic_sql(query_params)
        if not sql_query:
            logger.warning("Failed to build SQL query.")
            return {
                "answer": "ã“ã®è³ªå•ã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "isTable": False
            }
        logger.info(f"Generated parameterized SQL query:\n{sql_query}")
        logger.info(f"Query parameters: {sql_parameters}")

    else: # Using statcast master table
        sql_query, sql_parameters = _build_dynamic_statcast_sql(query_params)
        if not sql_query:
            logger.warning("Failed to build SQL query with statcast master table.")
            return {
                "answer": "ã“ã®è³ªå•ã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "isTable": False
            }
        logger.info(f"Generated parameterized SQL query (strategy: {query_strategy}):\n{sql_query}")
        logger.info(f"Query parameters: {sql_parameters}")

    # Step 3: Fetch data from BigQuery with parameterized query
    try:
        from google.cloud.bigquery import QueryJobConfig, ScalarQueryParameter, ArrayQueryParameter

        # BigQueryç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚’ä½œæˆ
        query_parameters_list = []

        for key, value in sql_parameters.items():
            if isinstance(value, list):
                # é…åˆ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: pitch_types, inningsï¼‰
                # é…åˆ—ã®è¦ç´ ã®å‹ã‚’åˆ¤å®š
                if value and isinstance(value[0], int):
                    param = ArrayQueryParameter(key, "INT64", value)
                    query_parameters_list.append(param)
                    logger.debug(f"Added array parameter: {key} = {value} (INT64)")
                else:
                    param = ArrayQueryParameter(key, "STRING", value)
                    query_parameters_list.append(param)
                    logger.debug(f"Added array parameter: {key} = {value} (STRING)")
            elif isinstance(value, int):
                # æ•´æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: season, inning, limitï¼‰
                param = ScalarQueryParameter(key, "INT64", value)
                query_parameters_list.append(param)
                logger.debug(f"Added scalar parameter: {key} = {value} (INT64)")
            else:
                # æ–‡å­—åˆ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: player_name, pitcher_throwsï¼‰
                param = ScalarQueryParameter(key, "STRING", str(value))
                query_parameters_list.append(param)
                logger.debug(f"Added scalar parameter: {key} = {value} (STRING)")

        job_config = QueryJobConfig(query_parameters=query_parameters_list)

        logger.info(f"Total query parameters configured: {len(query_parameters_list)}")
        logger.debug(f"Query parameters list: {[p.name for p in query_parameters_list]}")

        query_start = datetime.now()
        results_df = client.query(sql_query, job_config=job_config).to_dataframe()
        query_duration = (datetime.now() - query_start).total_seconds()

        logger.info(f"Query completed in {query_duration:.2f}s, fetched {len(results_df)} rows")

        # Performance warning for slow queries
        if query_duration > 10:  # 10ç§’ä»¥ä¸Š
            logger.warning(f"Slow query detected: {query_duration:.2f}s")
    except GoogleCloudError as e:
        logger.error(f"BigQuery query failed: {e}", exc_info=True)

        # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        error_message = "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        if "timeout" in str(e).lower():
            error_message += "ã‚¯ã‚¨ãƒªãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚æ¡ä»¶ã‚’çµã£ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
        elif "quota" in str(e).lower():
            error_message += "åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
        
        return {
            "answer": error_message,
            "isTable": False
        }
    
    if results_df.empty:
        return {
            "answer": "æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’å¤‰æ›´ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚",
            "isTable": False
        }
    
    # Step 4: Format response
    total_duration = (datetime.now() - query_start).total_seconds()
    logger.info(f"Total request processing time: {total_duration:.2f}s")
    
    # if output format is table
    if query_params.get("output_format") == "table":
        # Debug logging
        logger.info(f"DataFrame columns: {results_df.columns.tolist()}")
        logger.info(f"DataFrame dtypes: {results_df.dtypes.to_dict()}")
        logger.info(f"First row sample: {results_df.iloc[0].to_dict() if len(results_df) > 0 else 'No data'}")
        
        # Use centralized decimal columns configuration
        decimal_columns = DECIMAL_FORMAT_COLUMNS
        
        # Force decimal columns to have proper numeric types BEFORE converting to dict
        for col in decimal_columns:
            if col in results_df.columns:
                # Convert to numeric, coercing errors to NaN, then fill NaN with None
                results_df[col] = pd.to_numeric(results_df[col], errors='coerce')
                results_df[col] = results_df[col].where(pd.notnull(results_df[col]), None)
        
        # Convert to dictionary
        table_data = results_df.to_dict('records')
        
        # Post-process to ensure decimal formatting
        for row in table_data:
            for col in decimal_columns:
                if col in row and row[col] is not None:
                    try:
                        # Ensure it's a proper decimal number
                        value = float(row[col])
                        if not pd.isna(value):
                            row[col] = round(value, 3)
                        else:
                            row[col] = None
                    except (ValueError, TypeError) as e:
                        logger.warning(f"Could not convert {col} value {row[col]} to float: {e}")
                        # Keep original value
                        pass
        
        # Debug the final table data
        logger.info(f"Final table_data sample: {table_data[0] if table_data else 'No data'}")
        
        columns = [{"key": col, "label": col.replace('_', ' ').title()} for col in results_df.columns]
        
        # Check if single row result for transposition
        is_single_row = len(results_df) == 1
        
        # Add grouping metadata for career batting
        grouping_info = None
        if query_params.get("query_type") == "career_batting":
            # Get base info columns (name, team, etc.)
            base_columns = [col for col in results_df.columns if col in ['name', 'batter_name', 'career_last_team']]
            career_base_columns = [col for col in results_df.columns if col.startswith('career_') and '_at_' not in col and '_by_' not in col]
            risp_columns = [col for col in results_df.columns if '_at_risp' in col]
            bases_loaded_columns = [col for col in results_df.columns if '_at_bases_loaded' in col]
            
            grouping_info = {
                "type": "career_batting_chunks",
                "groups": [
                    {
                        "name": "Career Stats",
                        "columns": base_columns + career_base_columns
                    },
                    {
                        "name": "Career RISP Stats", 
                        "columns": risp_columns
                    },
                    {
                        "name": "Career Bases Loaded Stats",
                        "columns": bases_loaded_columns
                    }
                ]
            }
        
        return {
            "answer": f"ä»¥ä¸‹ã¯{len(results_df)}ä»¶ã®çµæœã§ã™ï¼š",
            "isTable": True,
            "isTransposed": is_single_row,
            "tableData": table_data,
            "columns": columns,
            "decimalColumns": [col for col in results_df.columns if col in DECIMAL_FORMAT_COLUMNS],
            "grouping": grouping_info
        }

    # Step 4: Generate final response with LLM
    else:
        logger.info("Generating final response with LLM.")
        final_response = _generate_final_response_with_llm(query, results_df)
        
        # Try to enhance with chart data
        from .simple_chart_service import enhance_response_with_simple_chart
        try:
            chart_data = enhance_response_with_simple_chart(
                query, query_params, results_df, season
            )
            
            if chart_data:
                # Return response with chart data only (minimal text)
                response = {
                    "answer": "ğŸ“ˆ",  # Just chart emoji to avoid empty content message
                    "isTable": False
                }
                response.update(chart_data)
                return response
        except Exception as e:
            logger.warning(f"Chart enhancement failed: {e}")
        
        # Return regular response if no chart enhancement
        return {
            "answer": final_response,
            "isTable": False
        }


def get_ai_response_with_simple_chart(query: str, season: Optional[int] = None) -> Optional[Dict[str, Any]]:
    """æ—¢å­˜é–¢æ•°ã‚’æ‹¡å¼µã—ã¦ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ¼ãƒˆå¯¾å¿œ"""
    
    # Just call the existing function for now - we'll integrate chart logic directly into it
    return get_ai_response_for_qna_enhanced(query, season)